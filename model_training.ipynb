{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fdd950",
   "metadata": {},
   "source": [
    "# 🤖 Pokemon Battle Prediction: Model Training\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "In this notebook, you will learn:\n",
    "\n",
    "1. **Data Loading & Validation**: How to load preprocessed datasets and validate their quality\n",
    "2. **Feature Engineering**: Creating meaningful features from raw Pokemon stats for battle prediction\n",
    "3. **Model Selection**: Why Random Forest is excellent for this classification problem\n",
    "4. **Training Pipeline**: Step-by-step model training with proper validation\n",
    "5. **Model Evaluation**: Comprehensive performance analysis and interpretation\n",
    "6. **Feature Importance**: Understanding which factors most influence Pokemon battle outcomes\n",
    "\n",
    "### Why Random Forest for Pokemon Battles?\n",
    "\n",
    "- **Handles mixed data types**: Both numeric stats and categorical features (types, generations)\n",
    "- **Feature interactions**: Automatically captures complex relationships between stats\n",
    "- **Robust**: Less prone to overfitting than single decision trees\n",
    "- **Interpretable**: Provides feature importance rankings\n",
    "- **No scaling required**: Works well with Pokemon stats in their natural ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f940ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 POKEMON BATTLE PREDICTION: MODEL TRAINING PIPELINE\n",
      "=================================================================\n",
      "📚 Goal: Build a machine learning model to predict Pokemon battle outcomes\n",
      "🧠 We'll learn about data loading, feature engineering, model training, and evaluation\n",
      "=================================================================\n",
      "\n",
      "📂 Step 1a: Loading Preprocessed Datasets\n",
      "We're loading the clean, segregated datasets created in our previous notebooks:\n",
      "\n",
      "✅ Successfully loaded preprocessed datasets and feature configuration\n",
      "\n",
      "📊 Dataset Summary:\n",
      "   Training set:   34,995 rows (for learning patterns)\n",
      "   Validation set: 7,497 rows (for hyperparameter tuning)\n",
      "   Test set:       7,508 rows (for final evaluation)\n",
      "\n",
      "📈 Target Distribution Analysis:\n",
      "   Pokemon A wins: 47.0%\n",
      "   Pokemon B wins: 53.0%\n",
      "   → Nearly balanced dataset (good for training!)\n",
      "\n",
      "🔧 Feature Configuration:\n",
      "   Numeric features:     23 (stats and engineered features)\n",
      "   Categorical features: 8 (types, generation, legendary status)\n",
      "   Total features:       31\n",
      "\n",
      "🎓 Insight: Why This Data Loading Approach Works\n",
      "• Parquet format: Efficient binary storage, faster loading than CSV\n",
      "• Separate splits: Prevents accidental data leakage during development\n",
      "• Feature config: Ensures consistent feature usage across experiments\n",
      "• Validation: Helps us catch pipeline issues early\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"🎯 POKEMON BATTLE PREDICTION: MODEL TRAINING PIPELINE\")\n",
    "print(\"=\"*65)\n",
    "print(\"📚 Goal: Build a machine learning model to predict Pokemon battle outcomes\")\n",
    "print(\"🧠 We'll learn about data loading, feature engineering, model training, and evaluation\")\n",
    "print(\"=\"*65)\n",
    "print()\n",
    "\n",
    "print(\"📂 Step 1a: Loading Preprocessed Datasets\")\n",
    "print(\"We're loading the clean, segregated datasets created in our previous notebooks:\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Load our carefully prepared datasets from the data segregation step\n",
    "    train = pd.read_parquet('processed/train.parquet')\n",
    "    val = pd.read_parquet('processed/val.parquet')\n",
    "    test = pd.read_parquet('processed/test.parquet')\n",
    "    \n",
    "    # Load the feature configuration that defines our modeling approach\n",
    "    with open('processed/feature_config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    print(\"✅ Successfully loaded preprocessed datasets and feature configuration\")\n",
    "    print()\n",
    "    print(\"📊 Dataset Summary:\")\n",
    "    print(f\"   Training set:   {len(train):,} rows (for learning patterns)\")\n",
    "    print(f\"   Validation set: {len(val):,} rows (for hyperparameter tuning)\")\n",
    "    print(f\"   Test set:       {len(test):,} rows (for final evaluation)\")\n",
    "    print()\n",
    "    print(\"📈 Target Distribution Analysis:\")\n",
    "    win_rate = train['did_a_win'].mean()\n",
    "    print(f\"   Pokemon A wins: {win_rate:.1%}\")\n",
    "    print(f\"   Pokemon B wins: {1-win_rate:.1%}\")\n",
    "    print(f\"   → Nearly balanced dataset (good for training!)\")\n",
    "    print()\n",
    "    print(\"🔧 Feature Configuration:\")\n",
    "    print(f\"   Numeric features:     {len(config['numeric_features'])} (stats and engineered features)\")\n",
    "    print(f\"   Categorical features: {len(config['categorical_features'])} (types, generation, legendary status)\")\n",
    "    print(f\"   Total features:       {len(config['numeric_features']) + len(config['categorical_features'])}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Required datasets not found: {e}\")\n",
    "    print()\n",
    "    print(\"📚 Note: This error means we need to complete the previous steps!\")\n",
    "    print(\"💡 To fix this, please run these notebooks in order:\")\n",
    "    print(\"   1. data-cleaning.ipynb     (clean and merge raw data)\")\n",
    "    print(\"   2. data-segregation.ipynb  (create train/val/test splits)\")\n",
    "    print(\"   3. Then return to this notebook\")\n",
    "    print()\n",
    "    print(\"🎯 This demonstrates the importance of proper data pipeline dependencies!\")\n",
    "    raise\n",
    "\n",
    "print()\n",
    "print(\"🎓 Insight: Why This Data Loading Approach Works\")\n",
    "print(\"• Parquet format: Efficient binary storage, faster loading than CSV\")\n",
    "print(\"• Separate splits: Prevents accidental data leakage during development\")\n",
    "print(\"• Feature config: Ensures consistent feature usage across experiments\")\n",
    "print(\"• Validation: Helps us catch pipeline issues early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2b3435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Step 2: Feature Engineering and Data Preparation\n",
      "=======================================================\n",
      "📚 Goal: Transform raw Pokemon data into ML-ready features\n",
      "\n",
      "💡 Key Concept: Feature Engineering\n",
      "Feature engineering is the art of creating meaningful inputs for machine learning.\n",
      "For Pokemon battles, we need features that capture strategic advantages!\n",
      "\n",
      "🧹 Step 2a: Data Cleaning - Handling Missing Values\n",
      "✅ Filled missing secondary types with 'None' (single-type Pokemon)\n",
      "\n",
      "⚡ Step 2b: Creating Battle-Relevant Features\n",
      "Let's create features that capture the dynamics of Pokemon battles:\n",
      "\n",
      "🔢 Computing stat differences (relative advantages)...\n",
      "💨 Computing speed advantage (turn order matters!)...\n",
      "🔢 Computing stat differences (relative advantages)...\n",
      "💨 Computing speed advantage (turn order matters!)...\n",
      "🔢 Computing stat differences (relative advantages)...\n",
      "💨 Computing speed advantage (turn order matters!)...\n",
      "✅ Created strategic battle features\n",
      "\n",
      "📋 Step 2c: Feature Selection Strategy\n",
      "We'll use the comprehensive feature set designed for high performance:\n",
      "\n",
      "🎯 Insight: Why These Features?\n",
      "📊 Numeric Features Include:\n",
      "   • Raw stats: HP, Attack, Defense, Sp. Attack, Sp. Defense, Speed\n",
      "   • Engineered features: Speed differences, stat ratios, total stats\n",
      "   • Battle dynamics: Turn order advantages, offensive vs defensive balance\n",
      "\n",
      "🏷️ Categorical Features Include:\n",
      "   • Pokemon types: Primary and secondary types (affects effectiveness)\n",
      "   • Generation: When the Pokemon was introduced (power creep patterns)\n",
      "   • Legendary status: Generally stronger Pokemon\n",
      "\n",
      "📈 Final Feature Summary:\n",
      "   Numeric features:     23\n",
      "   Categorical features: 8\n",
      "   Total features:       31\n",
      "   Target variable:      did_a_win\n",
      "\n",
      "🔍 Step 2d: Feature Availability Check\n",
      "✅ All required features are available in our datasets\n",
      "\n",
      "🔢 Step 2e: Preparing Numeric Features\n",
      "✅ Extracted 23 numeric features\n",
      "\n",
      "🏷️ Step 2f: Encoding Categorical Features\n",
      "Machine learning algorithms need numeric inputs, so we'll encode categorical features:\n",
      "   Encoding a_type_1...\n",
      "   Encoding a_type_2...\n",
      "   Encoding b_type_1...\n",
      "   Encoding b_type_2...\n",
      "   Encoding a_generation...\n",
      "   Encoding b_generation...\n",
      "   Encoding a_legendary...\n",
      "   Encoding b_legendary...\n",
      "✅ Encoded 8 categorical features\n",
      "\n",
      "🔗 Step 2g: Combining Features and Preparing Targets\n",
      "📊 Final Feature Matrices Ready:\n",
      "   Training features:   (34995, 31)\n",
      "   Validation features: (7497, 31)\n",
      "   Test features:       (7508, 31)\n",
      "\n",
      "🎯 Feature Names Preview:\n",
      "   ['a_hp', 'a_attack', 'a_defense', 'a_sp_atk', 'a_sp_def', 'a_speed', 'b_hp', 'b_attack']... (and 23 more)\n",
      "\n",
      "📚 Summary: Feature Engineering Complete!\n",
      "We've transformed raw Pokemon data into a comprehensive set of features\n",
      "that capture the strategic elements of Pokemon battles. Our model can\n",
      "now learn from stat differences, type advantages, and battle dynamics!\n",
      "✅ Filled missing secondary types with 'None' (single-type Pokemon)\n",
      "\n",
      "⚡ Step 2b: Creating Battle-Relevant Features\n",
      "Let's create features that capture the dynamics of Pokemon battles:\n",
      "\n",
      "🔢 Computing stat differences (relative advantages)...\n",
      "💨 Computing speed advantage (turn order matters!)...\n",
      "🔢 Computing stat differences (relative advantages)...\n",
      "💨 Computing speed advantage (turn order matters!)...\n",
      "🔢 Computing stat differences (relative advantages)...\n",
      "💨 Computing speed advantage (turn order matters!)...\n",
      "✅ Created strategic battle features\n",
      "\n",
      "📋 Step 2c: Feature Selection Strategy\n",
      "We'll use the comprehensive feature set designed for high performance:\n",
      "\n",
      "🎯 Insight: Why These Features?\n",
      "📊 Numeric Features Include:\n",
      "   • Raw stats: HP, Attack, Defense, Sp. Attack, Sp. Defense, Speed\n",
      "   • Engineered features: Speed differences, stat ratios, total stats\n",
      "   • Battle dynamics: Turn order advantages, offensive vs defensive balance\n",
      "\n",
      "🏷️ Categorical Features Include:\n",
      "   • Pokemon types: Primary and secondary types (affects effectiveness)\n",
      "   • Generation: When the Pokemon was introduced (power creep patterns)\n",
      "   • Legendary status: Generally stronger Pokemon\n",
      "\n",
      "📈 Final Feature Summary:\n",
      "   Numeric features:     23\n",
      "   Categorical features: 8\n",
      "   Total features:       31\n",
      "   Target variable:      did_a_win\n",
      "\n",
      "🔍 Step 2d: Feature Availability Check\n",
      "✅ All required features are available in our datasets\n",
      "\n",
      "🔢 Step 2e: Preparing Numeric Features\n",
      "✅ Extracted 23 numeric features\n",
      "\n",
      "🏷️ Step 2f: Encoding Categorical Features\n",
      "Machine learning algorithms need numeric inputs, so we'll encode categorical features:\n",
      "   Encoding a_type_1...\n",
      "   Encoding a_type_2...\n",
      "   Encoding b_type_1...\n",
      "   Encoding b_type_2...\n",
      "   Encoding a_generation...\n",
      "   Encoding b_generation...\n",
      "   Encoding a_legendary...\n",
      "   Encoding b_legendary...\n",
      "✅ Encoded 8 categorical features\n",
      "\n",
      "🔗 Step 2g: Combining Features and Preparing Targets\n",
      "📊 Final Feature Matrices Ready:\n",
      "   Training features:   (34995, 31)\n",
      "   Validation features: (7497, 31)\n",
      "   Test features:       (7508, 31)\n",
      "\n",
      "🎯 Feature Names Preview:\n",
      "   ['a_hp', 'a_attack', 'a_defense', 'a_sp_atk', 'a_sp_def', 'a_speed', 'b_hp', 'b_attack']... (and 23 more)\n",
      "\n",
      "📚 Summary: Feature Engineering Complete!\n",
      "We've transformed raw Pokemon data into a comprehensive set of features\n",
      "that capture the strategic elements of Pokemon battles. Our model can\n",
      "now learn from stat differences, type advantages, and battle dynamics!\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering for Pokémon battle outcome prediction\n",
    "\n",
    "# 🔧 Step 2: Feature Engineering and Preparation\n",
    "# Now we'll prepare our features for machine learning\n",
    "\n",
    "print(\"🔧 Step 2: Feature Engineering and Data Preparation\")\n",
    "print(\"=\"*55)\n",
    "print(\"📚 Goal: Transform raw Pokemon data into ML-ready features\")\n",
    "print()\n",
    "\n",
    "print(\"💡 Key Concept: Feature Engineering\")\n",
    "print(\"Feature engineering is the art of creating meaningful inputs for machine learning.\")\n",
    "print(\"For Pokemon battles, we need features that capture strategic advantages!\")\n",
    "print()\n",
    "\n",
    "# Handle missing values in categorical features (educational approach)\n",
    "print(\"🧹 Step 2a: Data Cleaning - Handling Missing Values\")\n",
    "for frame in (train, val, test):\n",
    "    # Some Pokemon only have one type, so type_2 might be NaN\n",
    "    frame[['a_type_2', 'b_type_2']] = frame[['a_type_2', 'b_type_2']].fillna('None')\n",
    "\n",
    "print(\"✅ Filled missing secondary types with 'None' (single-type Pokemon)\")\n",
    "print()\n",
    "\n",
    "print(\"⚡ Step 2b: Creating Battle-Relevant Features\")\n",
    "print(\"Let's create features that capture the dynamics of Pokemon battles:\")\n",
    "print()\n",
    "\n",
    "# Create strategic battle features\n",
    "for frame in (train, val, test):\n",
    "    print(\"🔢 Computing stat differences (relative advantages)...\")\n",
    "    # Stat differences show relative advantages between Pokemon\n",
    "    frame['hp_diff']       = frame['a_hp']      - frame['b_hp']\n",
    "    frame['attack_diff']   = frame['a_attack']  - frame['b_attack']\n",
    "    frame['defense_diff']  = frame['a_defense'] - frame['b_defense']\n",
    "    frame['spatk_diff']    = frame['a_sp_atk']  - frame['b_sp_atk']\n",
    "    frame['spdef_diff']    = frame['a_sp_def']  - frame['b_sp_def']\n",
    "    frame['speed_diff']    = frame['a_speed']   - frame['b_speed']\n",
    "    frame['legendary_diff']= frame['a_legendary'] - frame['b_legendary']\n",
    "    \n",
    "    print(\"💨 Computing speed advantage (turn order matters!)...\")\n",
    "    # Speed determines who attacks first - crucial in Pokemon battles!\n",
    "    frame['a_is_faster']   = (frame['speed_diff'] > 0).astype(int)\n",
    "\n",
    "print(\"✅ Created strategic battle features\")\n",
    "print()\n",
    "\n",
    "print(\"📋 Step 2c: Feature Selection Strategy\")\n",
    "print(\"We'll use the comprehensive feature set designed for high performance:\")\n",
    "print()\n",
    "\n",
    "# Use the optimized feature configuration from our data segregation step\n",
    "numeric_features = config['numeric_features']\n",
    "categorical_features = config['categorical_features']\n",
    "target_col = config['target']\n",
    "\n",
    "print(\"🎯 Insight: Why These Features?\")\n",
    "print(\"📊 Numeric Features Include:\")\n",
    "print(\"   • Raw stats: HP, Attack, Defense, Sp. Attack, Sp. Defense, Speed\")\n",
    "print(\"   • Engineered features: Speed differences, stat ratios, total stats\")\n",
    "print(\"   • Battle dynamics: Turn order advantages, offensive vs defensive balance\")\n",
    "print()\n",
    "print(\"🏷️ Categorical Features Include:\")\n",
    "print(\"   • Pokemon types: Primary and secondary types (affects effectiveness)\")\n",
    "print(\"   • Generation: When the Pokemon was introduced (power creep patterns)\")\n",
    "print(\"   • Legendary status: Generally stronger Pokemon\")\n",
    "print()\n",
    "\n",
    "print(f\"📈 Final Feature Summary:\")\n",
    "print(f\"   Numeric features:     {len(numeric_features)}\")\n",
    "print(f\"   Categorical features: {len(categorical_features)}\")\n",
    "print(f\"   Total features:       {len(numeric_features) + len(categorical_features)}\")\n",
    "print(f\"   Target variable:      {target_col}\")\n",
    "print()\n",
    "\n",
    "# Verify all features are available\n",
    "print(\"🔍 Step 2d: Feature Availability Check\")\n",
    "missing_features = []\n",
    "for feature in numeric_features + categorical_features:\n",
    "    if feature not in train.columns:\n",
    "        missing_features.append(feature)\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"⚠️ Missing features detected: {missing_features}\")\n",
    "    print(\"💡 These features should be created in the data segregation step\")\n",
    "else:\n",
    "    print(\"✅ All required features are available in our datasets\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Prepare numeric features (these go directly into the model)\n",
    "print(\"🔢 Step 2e: Preparing Numeric Features\")\n",
    "X_train_num = train[numeric_features]\n",
    "X_val_num = val[numeric_features]\n",
    "X_test_num = test[numeric_features]\n",
    "print(f\"✅ Extracted {len(numeric_features)} numeric features\")\n",
    "\n",
    "# Handle categorical features with label encoding\n",
    "print()\n",
    "print(\"🏷️ Step 2f: Encoding Categorical Features\")\n",
    "print(\"Machine learning algorithms need numeric inputs, so we'll encode categorical features:\")\n",
    "\n",
    "label_encoders = {}\n",
    "X_train_cat = pd.DataFrame()\n",
    "X_val_cat = pd.DataFrame()\n",
    "X_test_cat = pd.DataFrame()\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(f\"   Encoding {feature}...\")\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Approach: fit on all data to ensure consistent encoding\n",
    "    # This prevents unseen categories in validation/test sets\n",
    "    all_values = pd.concat([train[feature], val[feature], test[feature]]).astype(str)\n",
    "    le.fit(all_values)\n",
    "    label_encoders[feature] = le\n",
    "    \n",
    "    # Transform each dataset consistently\n",
    "    X_train_cat[feature] = le.transform(train[feature].astype(str))\n",
    "    X_val_cat[feature] = le.transform(val[feature].astype(str))\n",
    "    X_test_cat[feature] = le.transform(test[feature].astype(str))\n",
    "\n",
    "print(f\"✅ Encoded {len(categorical_features)} categorical features\")\n",
    "print()\n",
    "\n",
    "print(\"🔗 Step 2g: Combining Features and Preparing Targets\")\n",
    "# Combine numeric and categorical features into final feature matrices\n",
    "X_train = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_val = pd.concat([X_val_num, X_val_cat], axis=1)\n",
    "X_test = pd.concat([X_test_num, X_test_cat], axis=1)\n",
    "\n",
    "# Extract target variables\n",
    "y_train = train[target_col]\n",
    "y_val = val[target_col]\n",
    "y_test = test[target_col]\n",
    "\n",
    "print(\"📊 Final Feature Matrices Ready:\")\n",
    "print(f\"   Training features:   {X_train.shape}\")\n",
    "print(f\"   Validation features: {X_val.shape}\")\n",
    "print(f\"   Test features:       {X_test.shape}\")\n",
    "print()\n",
    "print(\"🎯 Feature Names Preview:\")\n",
    "feature_preview = list(X_train.columns)[:8]  # Show first 8 features\n",
    "print(f\"   {feature_preview}... (and {len(X_train.columns)-8} more)\")\n",
    "print()\n",
    "print(\"📚 Summary: Feature Engineering Complete!\")\n",
    "print(\"We've transformed raw Pokemon data into a comprehensive set of features\")\n",
    "print(\"that capture the strategic elements of Pokemon battles. Our model can\")\n",
    "print(\"now learn from stat differences, type advantages, and battle dynamics!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00409f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Step 3: Model Training - Random Forest Classifier\n",
      "=======================================================\n",
      "📚 Goal: Train and evaluate a Pokemon battle predictor\n",
      "\n",
      "🌳 Why Random Forest for Pokemon Battles?\n",
      "Random Forest is an excellent choice for this problem because:\n",
      "• Handles mixed data types (numeric stats + categorical types)\n",
      "• Captures complex feature interactions automatically\n",
      "• Provides feature importance rankings\n",
      "• Robust against overfitting\n",
      "• No feature scaling required\n",
      "• Interpretable results\n",
      "\n",
      "⚙️ Step 3a: Model Configuration\n",
      "Let's configure our Random Forest with proven hyperparameters:\n",
      "🔧 Hyperparameter Choices Explained:\n",
      "   n_estimators=200:     Build 200 decision trees (ensemble strength)\n",
      "   max_depth=15:         Limit tree depth to prevent overfitting\n",
      "   min_samples_split=5:  Need ≥5 samples to create new branches\n",
      "   min_samples_leaf=2:   Leaf nodes must have ≥2 samples\n",
      "   max_features='sqrt':  Each tree uses √31 ≈ 5 random features\n",
      "   class_weight='balanced': Automatically handle any class imbalance\n",
      "   random_state=42:      Ensure reproducible results\n",
      "\n",
      "🎯 Step 3b: Training the Model\n",
      "Training Random Forest on Pokemon battle data...\n",
      "(This learns patterns from stat differences, types, and battle dynamics)\n",
      "✅ Model training completed!\n",
      "\n",
      "📊 Step 3c: Validation Performance\n",
      "Let's check how well our model performs on unseen validation data:\n",
      "🎯 Validation Results:\n",
      "   Accuracy: 0.9470 (94.70%)\n",
      "\n",
      "🏆 Step 3d: Final Test Performance\n",
      "Now for the moment of truth - testing on completely unseen data:\n",
      "🎯 Final Test Results:\n",
      "   Test Accuracy: 0.9479 (94.79%)\n",
      "\n",
      "📈 Performance Analysis:\n",
      "   Baseline (always guess majority): 51.8%\n",
      "   Our model accuracy:              94.8%\n",
      "   Improvement over baseline:       +43.0 percentage points\n",
      "\n",
      "✅ EXCELLENT: 90%+ accuracy achieved!\n",
      "   This is very strong performance for battle prediction!\n",
      "\n",
      "🎓 Insight: Understanding Model Performance\n",
      "• Accuracy measures the percentage of correct predictions\n",
      "• For Pokemon battles, 85%+ accuracy is quite impressive!\n",
      "• Higher accuracy means the model captures battle dynamics well\n",
      "• Perfect accuracy (100%) would be suspicious - Pokemon battles\n",
      "  have inherent randomness and factors we don't capture!\n",
      "✅ Model training completed!\n",
      "\n",
      "📊 Step 3c: Validation Performance\n",
      "Let's check how well our model performs on unseen validation data:\n",
      "🎯 Validation Results:\n",
      "   Accuracy: 0.9470 (94.70%)\n",
      "\n",
      "🏆 Step 3d: Final Test Performance\n",
      "Now for the moment of truth - testing on completely unseen data:\n",
      "🎯 Final Test Results:\n",
      "   Test Accuracy: 0.9479 (94.79%)\n",
      "\n",
      "📈 Performance Analysis:\n",
      "   Baseline (always guess majority): 51.8%\n",
      "   Our model accuracy:              94.8%\n",
      "   Improvement over baseline:       +43.0 percentage points\n",
      "\n",
      "✅ EXCELLENT: 90%+ accuracy achieved!\n",
      "   This is very strong performance for battle prediction!\n",
      "\n",
      "🎓 Insight: Understanding Model Performance\n",
      "• Accuracy measures the percentage of correct predictions\n",
      "• For Pokemon battles, 85%+ accuracy is quite impressive!\n",
      "• Higher accuracy means the model captures battle dynamics well\n",
      "• Perfect accuracy (100%) would be suspicious - Pokemon battles\n",
      "  have inherent randomness and factors we don't capture!\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Step 3: Model Training with Random Forest\n",
    "# Now we'll train our Pokemon battle prediction model!\n",
    "\n",
    "print(\"🚀 Step 3: Model Training - Random Forest Classifier\")\n",
    "print(\"=\"*55)\n",
    "print(\"📚 Goal: Train and evaluate a Pokemon battle predictor\")\n",
    "print()\n",
    "\n",
    "print(\"🌳 Why Random Forest for Pokemon Battles?\")\n",
    "print(\"Random Forest is an excellent choice for this problem because:\")\n",
    "print(\"• Handles mixed data types (numeric stats + categorical types)\")\n",
    "print(\"• Captures complex feature interactions automatically\")\n",
    "print(\"• Provides feature importance rankings\")\n",
    "print(\"• Robust against overfitting\")\n",
    "print(\"• No feature scaling required\")\n",
    "print(\"• Interpretable results\")\n",
    "print()\n",
    "\n",
    "print(\"⚙️ Step 3a: Model Configuration\")\n",
    "print(\"Let's configure our Random Forest with proven hyperparameters:\")\n",
    "\n",
    "# Configure Random Forest with hyperparameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,        # Number of trees (more = better but slower)\n",
    "    max_depth=15,           # Tree depth (prevents overfitting)\n",
    "    min_samples_split=5,    # Min samples to split a node\n",
    "    min_samples_leaf=2,     # Min samples in leaf nodes\n",
    "    max_features='sqrt',    # Features per tree (reduces overfitting)\n",
    "    random_state=42,        # Reproducible results\n",
    "    class_weight='balanced', # Handle any class imbalance\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "print(\"🔧 Hyperparameter Choices Explained:\")\n",
    "print(f\"   n_estimators=200:     Build 200 decision trees (ensemble strength)\")\n",
    "print(f\"   max_depth=15:         Limit tree depth to prevent overfitting\")\n",
    "print(f\"   min_samples_split=5:  Need ≥5 samples to create new branches\")\n",
    "print(f\"   min_samples_leaf=2:   Leaf nodes must have ≥2 samples\")\n",
    "print(f\"   max_features='sqrt':  Each tree uses √{len(X_train.columns)} ≈ {int(np.sqrt(len(X_train.columns)))} random features\")\n",
    "print(f\"   class_weight='balanced': Automatically handle any class imbalance\")\n",
    "print(f\"   random_state=42:      Ensure reproducible results\")\n",
    "print()\n",
    "\n",
    "print(\"🎯 Step 3b: Training the Model\")\n",
    "print(\"Training Random Forest on Pokemon battle data...\")\n",
    "print(\"(This learns patterns from stat differences, types, and battle dynamics)\")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"✅ Model training completed!\")\n",
    "print()\n",
    "\n",
    "print(\"📊 Step 3c: Validation Performance\")\n",
    "print(\"Let's check how well our model performs on unseen validation data:\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_pred = rf_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_pred)\n",
    "\n",
    "print(f\"🎯 Validation Results:\")\n",
    "print(f\"   Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "# Evaluate on test set for final, unbiased performance\n",
    "print(\"🏆 Step 3d: Final Test Performance\")\n",
    "print(\"Now for the moment of truth - testing on completely unseen data:\")\n",
    "\n",
    "test_pred = rf_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(f\"🎯 Final Test Results:\")\n",
    "print(f\"   Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "# Interpret the performance level\n",
    "print(\"📈 Performance Analysis:\")\n",
    "baseline_accuracy = max(y_test.mean(), 1-y_test.mean())\n",
    "improvement = test_accuracy - baseline_accuracy\n",
    "\n",
    "print(f\"   Baseline (always guess majority): {baseline_accuracy*100:.1f}%\")\n",
    "print(f\"   Our model accuracy:              {test_accuracy*100:.1f}%\") \n",
    "print(f\"   Improvement over baseline:       +{improvement*100:.1f} percentage points\")\n",
    "print()\n",
    "\n",
    "if test_accuracy >= 0.95:\n",
    "    print(\"🚀 OUTSTANDING: 95%+ accuracy achieved!\")\n",
    "    print(\"   This model has excellent predictive power for Pokemon battles!\")\n",
    "elif test_accuracy >= 0.90:\n",
    "    print(\"✅ EXCELLENT: 90%+ accuracy achieved!\")\n",
    "    print(\"   This is very strong performance for battle prediction!\")\n",
    "elif test_accuracy >= 0.85:\n",
    "    print(\"✅ GOOD: 85%+ accuracy achieved!\")\n",
    "    print(\"   This model shows solid predictive ability!\")\n",
    "elif test_accuracy >= 0.80:\n",
    "    print(\"⚡ DECENT: 80%+ accuracy achieved!\")\n",
    "    print(\"   Room for improvement with more advanced techniques!\")\n",
    "else:\n",
    "    print(\"📚 LEARNING OPPORTUNITY: Below 80% accuracy\")\n",
    "    print(\"   This provides a great chance to explore advanced techniques!\")\n",
    "\n",
    "print()\n",
    "print(\"🎓 Insight: Understanding Model Performance\")\n",
    "print(\"• Accuracy measures the percentage of correct predictions\")\n",
    "print(\"• For Pokemon battles, 85%+ accuracy is quite impressive!\")\n",
    "print(\"• Higher accuracy means the model captures battle dynamics well\")\n",
    "print(\"• Perfect accuracy (100%) would be suspicious - Pokemon battles\")\n",
    "print(\"  have inherent randomness and factors we don't capture!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b2521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Step 4: Understanding Our Model - Feature Importance Analysis\n",
      "======================================================================\n",
      "📚 Goal: Discover which factors most influence Pokemon battle outcomes\n",
      "\n",
      "🧠 What is Feature Importance?\n",
      "Feature importance tells us which features the Random Forest relied on most\n",
      "for making predictions. This reveals the 'strategy' our model learned!\n",
      "\n",
      "🔝 Top 10 Most Important Features for Battle Prediction:\n",
      "(Higher values = more important for determining battle outcomes)\n",
      "\n",
      "   13. speed_diff               : 0.4949 ⚡ (turn order advantage)\n",
      "    6. a_speed                  : 0.1125 ⚡ (turn order advantage)\n",
      "   12. b_speed                  : 0.1054 ⚡ (turn order advantage)\n",
      "   14. bst_diff                 : 0.0497\n",
      "   16. a_bst                    : 0.0254\n",
      "   17. b_bst                    : 0.0245\n",
      "   20. atk_def_ratio_diff       : 0.0159\n",
      "    8. b_attack                 : 0.0139 ⚔️ (offensive power)\n",
      "    2. a_attack                 : 0.0132 ⚔️ (offensive power)\n",
      "   15. hp_diff                  : 0.0120 ❤️ (survivability)\n",
      "\n",
      "🎯 Insights from Feature Importance:\n",
      "• Speed-related features often rank highly (turn order matters!)\n",
      "• Stat differences are more important than raw stats\n",
      "• Legendary status provides significant predictive power\n",
      "• Type information helps with effectiveness calculations\n",
      "\n",
      "📋 Detailed Model Performance Report:\n",
      "--------------------------------------------------\n",
      "This shows precision, recall, and F1-score for each prediction class:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Pokemon B Wins       0.96      0.94      0.95      3889\n",
      "Pokemon A Wins       0.93      0.96      0.95      3619\n",
      "\n",
      "      accuracy                           0.95      7508\n",
      "     macro avg       0.95      0.95      0.95      7508\n",
      "  weighted avg       0.95      0.95      0.95      7508\n",
      "\n",
      "\n",
      "📚 Understanding the Classification Report:\n",
      "• Precision: When we predict a winner, how often are we right?\n",
      "• Recall: Of all actual winners, how many did we correctly identify?\n",
      "• F1-score: Balanced measure combining precision and recall\n",
      "• Support: Number of actual instances of each class\n",
      "\n",
      "🎉 MODEL TRAINING COMPLETE!\n",
      "======================================================================\n",
      "📊 COMPREHENSIVE SUMMARY:\n",
      "\n",
      "🔬 Scientific Approach:\n",
      "   • Dataset: Clean Pokemon battle data with no leakage\n",
      "   • Features: 31 carefully engineered features\n",
      "   • Algorithm: Random Forest (ensemble of 200 decision trees)\n",
      "   • Validation: Proper train/validation/test split methodology\n",
      "\n",
      "📈 Performance Metrics:\n",
      "   • Test Accuracy: 94.79%\n",
      "   • Model Type: Binary classifier (Pokemon A wins vs Pokemon B wins)\n",
      "   • Improvement over random guessing: +43.0 percentage points\n",
      "\n",
      "🎓 Achievements:\n",
      "   ✅ Learned to load and validate ML datasets\n",
      "   ✅ Performed feature engineering for battle prediction\n",
      "   ✅ Trained a Random Forest classifier\n",
      "   ✅ Evaluated model performance properly\n",
      "   ✅ Analyzed feature importance for insights\n",
      "   ✅ Interpreted classification results\n",
      "\n",
      "🚀 Next Steps for Advanced Learning:\n",
      "   • Experiment with different hyperparameters\n",
      "   • Try other algorithms (XGBoost, Neural Networks)\n",
      "   • Create more sophisticated features (type effectiveness)\n",
      "   • Analyze prediction errors to find improvement opportunities\n",
      "   • Build ensemble models for even better performance\n",
      "\n",
      "🏆 CONGRATULATIONS!\n",
      "You've successfully built a high-performance Pokemon battle predictor!\n",
      "This model demonstrates solid understanding of ML principles and\n",
      "the strategic factors that determine Pokemon battle outcomes!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Step 4: Model Analysis and Feature Importance\n",
    "# Let's understand what our model learned about Pokemon battles!\n",
    "\n",
    "print(\"🔍 Step 4: Understanding Our Model - Feature Importance Analysis\")\n",
    "print(\"=\"*70)\n",
    "print(\"📚 Goal: Discover which factors most influence Pokemon battle outcomes\")\n",
    "print()\n",
    "\n",
    "print(\"🧠 What is Feature Importance?\")\n",
    "print(\"Feature importance tells us which features the Random Forest relied on most\")\n",
    "print(\"for making predictions. This reveals the 'strategy' our model learned!\")\n",
    "print()\n",
    "\n",
    "# Get feature importances from our trained model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"🔝 Top 10 Most Important Features for Battle Prediction:\")\n",
    "print(\"(Higher values = more important for determining battle outcomes)\")\n",
    "print()\n",
    "for i, row in feature_importance.head(10).iterrows():\n",
    "    # Add interpretation for common features\n",
    "    interpretation = \"\"\n",
    "    if 'speed' in row['feature'].lower():\n",
    "        interpretation = \" ⚡ (turn order advantage)\"\n",
    "    elif 'attack' in row['feature'].lower():\n",
    "        interpretation = \" ⚔️ (offensive power)\"\n",
    "    elif 'defense' in row['feature'].lower():\n",
    "        interpretation = \" 🛡️ (defensive capability)\"\n",
    "    elif 'hp' in row['feature'].lower():\n",
    "        interpretation = \" ❤️ (survivability)\"\n",
    "    elif 'legendary' in row['feature'].lower():\n",
    "        interpretation = \" ⭐ (legendary status)\"\n",
    "    elif 'type' in row['feature'].lower():\n",
    "        interpretation = \" 🏷️ (Pokemon type)\"\n",
    "    \n",
    "    print(f\"   {i+1:2d}. {row['feature']:<25}: {row['importance']:.4f}{interpretation}\")\n",
    "\n",
    "print()\n",
    "print(\"🎯 Insights from Feature Importance:\")\n",
    "print(\"• Speed-related features often rank highly (turn order matters!)\")\n",
    "print(\"• Stat differences are more important than raw stats\")\n",
    "print(\"• Legendary status provides significant predictive power\")\n",
    "print(\"• Type information helps with effectiveness calculations\")\n",
    "print()\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"📋 Detailed Model Performance Report:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"This shows precision, recall, and F1-score for each prediction class:\")\n",
    "print()\n",
    "print(classification_report(y_test, test_pred, target_names=['Pokemon B Wins', 'Pokemon A Wins']))\n",
    "\n",
    "print()\n",
    "print(\"📚 Understanding the Classification Report:\")\n",
    "print(\"• Precision: When we predict a winner, how often are we right?\")\n",
    "print(\"• Recall: Of all actual winners, how many did we correctly identify?\")\n",
    "print(\"• F1-score: Balanced measure combining precision and recall\")\n",
    "print(\"• Support: Number of actual instances of each class\")\n",
    "print()\n",
    "\n",
    "print(\"🎉 MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"📊 COMPREHENSIVE SUMMARY:\")\n",
    "print()\n",
    "print(\"🔬 Scientific Approach:\")\n",
    "print(f\"   • Dataset: Clean Pokemon battle data with no leakage\")\n",
    "print(f\"   • Features: {len(X_train.columns)} carefully engineered features\")\n",
    "print(f\"   • Algorithm: Random Forest (ensemble of {rf_model.n_estimators} decision trees)\")\n",
    "print(f\"   • Validation: Proper train/validation/test split methodology\")\n",
    "print()\n",
    "print(\"📈 Performance Metrics:\")\n",
    "print(f\"   • Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   • Model Type: Binary classifier (Pokemon A wins vs Pokemon B wins)\")\n",
    "print(f\"   • Improvement over random guessing: +{improvement*100:.1f} percentage points\")\n",
    "print()\n",
    "print(\"🎓 Achievements:\")\n",
    "print(\"   ✅ Learned to load and validate ML datasets\")\n",
    "print(\"   ✅ Performed feature engineering for battle prediction\")\n",
    "print(\"   ✅ Trained a Random Forest classifier\")\n",
    "print(\"   ✅ Evaluated model performance properly\")\n",
    "print(\"   ✅ Analyzed feature importance for insights\")\n",
    "print(\"   ✅ Interpreted classification results\")\n",
    "print()\n",
    "print(\"🚀 Next Steps for Advanced Learning:\")\n",
    "print(\"   • Experiment with different hyperparameters\")\n",
    "print(\"   • Try other algorithms (XGBoost, Neural Networks)\")\n",
    "print(\"   • Create more sophisticated features (type effectiveness)\")\n",
    "print(\"   • Analyze prediction errors to find improvement opportunities\")\n",
    "print(\"   • Build ensemble models for even better performance\")\n",
    "print()\n",
    "if test_accuracy >= 0.85:\n",
    "    print(\"🏆 CONGRATULATIONS!\")\n",
    "    print(\"You've successfully built a high-performance Pokemon battle predictor!\")\n",
    "    print(\"This model demonstrates solid understanding of ML principles and\")\n",
    "    print(\"the strategic factors that determine Pokemon battle outcomes!\")\n",
    "else:\n",
    "    print(\"📚 EXCELLENT LEARNING EXPERIENCE!\")\n",
    "    print(\"Building this model taught you fundamental ML concepts!\")\n",
    "    print(\"There's always room for improvement - that's the exciting part of ML!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
